{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Understanding and Predicting Economic Development: A Machine Learning Approach**\n\nThis is a Jupyter notebook that presents the code and explanation for the execution of the data acquisition, cleaning and preprocessing and subsequent fitting of the machine learning model, both supervised and unsupervised models.\n\nThe author will present a markdown above each executed cell explaining the functions, input and output of the code being executed. \n\nPlease do not attempt to change any line of code within this file without a proper understanding of each line, else the entire code **might** break down.","metadata":{}},{"cell_type":"markdown","source":"# **CELL 1**\n\nThe cell below installs the World Bank library will is an API that gives us access into the World Bank Development Indicators Database. It also installs the fancyimpute library which is used later in the code to fill missing variables in the spooled dataset.\nThis cell is executed independently because Python Integrated Development Environments (IDEs) such as Anaconda and Pycharm do not usually have these libraries installed. ","metadata":{}},{"cell_type":"code","source":"#Install Required Libraries\n!pip install wbdata\n!pip install fancyimpute\n!pip install openpyxl","metadata":{"execution":{"iopub.status.busy":"2022-07-28T10:30:17.689484Z","iopub.execute_input":"2022-07-28T10:30:17.689958Z","iopub.status.idle":"2022-07-28T10:31:05.474288Z","shell.execute_reply.started":"2022-07-28T10:30:17.689823Z","shell.execute_reply":"2022-07-28T10:31:05.473472Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# **CELL 2**\n\nThe cell below imports the many libraries which will be required by functions and dataframes in the code below. Such libraries include Pandas for interacting with DataFrames, Sklearn for accessing Machine Learning Models and Seaborn or Matplotlib for plotting graphs. \n!!If any of these libraries cause an error in execution, kindly install the required library using the *!pip install XXX* protocol into your python version.","metadata":{}},{"cell_type":"code","source":"#Import Required Modules and Libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport wbdata    \nfrom fancyimpute import KNN\nfrom sklearn.preprocessing import StandardScaler\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.mixture import GaussianMixture\nimport sklearn.utils\nfrom sklearn.model_selection import train_test_split\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.datasets import make_classification\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2022-07-28T10:31:05.476156Z","iopub.execute_input":"2022-07-28T10:31:05.476415Z","iopub.status.idle":"2022-07-28T10:31:08.414087Z","shell.execute_reply.started":"2022-07-28T10:31:05.476383Z","shell.execute_reply":"2022-07-28T10:31:08.412908Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# **CELL 2**\n\nThe cell below initializes four variables into memory;\n* Indicators: This is a dictionary-type variables which includes the World Bank Designation for each of the variable which we are interested in using for our model and the associated name for the variable.\n* countries_list: This is a list-type variable of all 217 countries (economies) which the code will request their data from the World Bank API\n* developing_economies: This is a list-type variable that contains the names of all developing economies as classified by the World Economic Situation and Prospects 2022 report by the United Nations.\n* emerging economies: This is a list-type variable that contains the names of all transitioning economies as classified by the World Economic Situation and Prospects 2022 report by the United Nations.\n* developed_economies: This is a list-type variable that contains the names of all developed economies as classified by the World Economic Situation and Prospects 2022 report by the United Nations.\n","metadata":{}},{"cell_type":"code","source":"indicators = {\"NE.IMP.GNFS.KD\" : \"Imports of goods and services (constant 2015 US$)\",\n              \"NE.EXP.GNFS.KD\" : \"Exports of goods and services (constant 2015 US$)\",\n              \"NY.GDP.MKTP.KD\" : \"GDP (constant 2015 US$)\",\n              \"SP.POP.TOTL\" : \"Population, total\",\n              \"SH.XPD.GHED.GD.ZS\" : \"Domestic general government health expenditure (% of GDP)\",\n              \"SH.XPD.OOPC.CH.ZS\" : \"Out-of-pocket expenditure (% of current health expenditure)\",\n              \"SE.XPD.TOTL.GB.ZS\" : \"Government expenditure on education, total (% of government expenditure)\",\n              \"EG.USE.ELEC.KH.PC\" : \"Electric power consumption (kWh per capita)\",\n              \"NE.GDI.TOTL.ZS\" : \"Gross capital formation (% of GDP)\",\n              \"BN.KLT.DINV.CD\" : \"Foreign direct investment, net (BoP, current US$)\",\n              \"MS.MIL.XPND.GD.ZS\" : \"Military expenditure (% of GDP)\",\n              \"NY.GDP.PCAP.KD\" : \"GDP per capita (constant 2015 US$)\", \n              \"SL.UEM.TOTL.ZS\" : \"Unemployment, total (% of total labor force) (modeled ILO estimate)\",\n              \"SP.DYN.TFRT.IN\" : \"Fertility rate, total (births per woman)\",\n              \"SP.DYN.IMRT.IN\" : \"Mortality rate, infant (per 1,000 live births)\",\n              \"SP.DYN.LE00.IN\" : \"Life expectancy at birth, total (years)\",\n              \"SE.ENR.PRIM.FM.ZS\" : \"School enrollment, primary (gross), gender parity index (GPI)\",\n              \"NV.IND.TOTL.ZS\" : \"Industry (including construction), value added (% of GDP)\",\n              \"NV.IND.MANF.ZS\" : \"Manufacturing, value added (% of GDP)\",\n              \"IS.AIR.PSGR\" : \"Air transport, passengers carried\",\n              \"EN.ATM.CO2E.KT\" : \"CO2 emissions (kt)\",\n              \"NY.GDP.MINR.RT.ZS\" : \"Mineral rents (% of GDP)\",\n              \"TM.VAL.FOOD.ZS.UN\" : \"Food imports (% of merchandise imports)\",\n              \"IQ.CPA.TRAN.XQ\" : \"CPIA transparency, accountability, and corruption in the public sector rating (1=low to 6=high)\",\n              \"IQ.CPA.FINQ.XQ\" : \"CPIA quality of budgetary and financial management rating (1=low to 6=high)\",\n              \"IQ.CPA.PROP.XQ\" : \"CPIA property rights and rule-based governance rating (1=low to 6=high)\",     \n              \"IQ.CPA.TRAD.XQ\" : \"CPIA trade rating (1=low to 6=high)\"}\ncountries_list = [\"Afghanistan\",\"Albania\",\"Algeria\",\"American Samoa\",\"Andorra\",\"Angola\",\"Antigua and Barbuda\",\"Argentina\",\"Armenia\",\"Aruba\",\"Australia\",\"Austria\",\"Azerbaijan\",\"Bahamas, The\",\"Bahrain\",\"Bangladesh\",\"Barbados\",\"Belarus\",\"Belgium\",\"Belize\",\"Benin\",\"Bermuda\",\"Bhutan\",\"Bolivia\",\"Bosnia and Herzegovina\",\"Botswana\",\"Brazil\",\"British Virgin Islands\",\"Brunei Darussalam\",\"Bulgaria\",\"Burkina Faso\",\"Burundi\",\"Cabo Verde\",\"Cambodia\",\"Cameroon\",\"Canada\",\"Cayman Islands\",\"Central African Republic\",\"Chad\",\"Channel Islands\",\"Chile\",\"China\",\"Colombia\",\"Comoros\",\"Congo, Dem. Rep.\",\"Congo, Rep.\",\"Costa Rica\",\"Cote d'Ivoire\",\"Croatia\",\"Cuba\",\"Curacao\",\"Cyprus\",\"Czech Republic\",\"Denmark\",\"Djibouti\",\"Dominica\",\"Dominican Republic\",\"Ecuador\",\"Egypt, Arab Rep.\",\"El Salvador\",\"Equatorial Guinea\",\"Eritrea\",\"Estonia\",\"Eswatini\",\"Ethiopia\",\"Faroe Islands\",\"Fiji\",\"Finland\",\"France\",\"French Polynesia\",\"Gabon\",\"Gambia, The\",\"Georgia\",\"Germany\",\"Ghana\",\"Gibraltar\",\"Greece\",\"Greenland\",\"Grenada\",\"Guam\",\"Guatemala\",\"Guinea\",\"Guinea-Bissau\",\"Guyana\",\"Haiti\",\"Honduras\",\"Hong Kong SAR, China\",\"Hungary\",\"Iceland\",\"India\",\"Indonesia\",\"Iran, Islamic Rep.\",\"Iraq\",\"Ireland\",\"Isle of Man\",\"Israel\",\"Italy\",\"Jamaica\",\"Japan\",\"Jordan\",\"Kazakhstan\",\"Kenya\",\"Kiribati\",\"Korea, Dem. People's Rep.\",\"Korea, Rep.\",\"Kosovo\",\"Kuwait\",\"Kyrgyz Republic\",\"Lao PDR\",\"Latvia\",\"Lebanon\",\"Lesotho\",\"Liberia\",\"Libya\",\"Liechtenstein\",\"Lithuania\",\"Luxembourg\",\"Macao SAR, China\",\"Madagascar\",\"Malawi\",\"Malaysia\",\"Maldives\",\"Mali\",\"Malta\",\"Marshall Islands\",\"Mauritania\",\"Mauritius\",\"Mexico\",\"Micronesia, Fed. Sts.\",\"Moldova\",\"Monaco\",\"Mongolia\",\"Montenegro\",\"Morocco\",\"Mozambique\",\"Myanmar\",\"Namibia\",\"Nauru\",\"Nepal\",\"Netherlands\",\"New Caledonia\",\"New Zealand\",\"Nicaragua\",\"Niger\",\"Nigeria\",\"North Macedonia\",\"Northern Mariana Islands\",\"Norway\",\"Oman\",\"Pakistan\",\"Palau\",\"Panama\",\"Papua New Guinea\",\"Paraguay\",\"Peru\",\"Philippines\",\"Poland\",\"Portugal\",\"Puerto Rico\",\"Qatar\",\"Romania\",\"Russian Federation\",\"Rwanda\",\"Samoa\",\"San Marino\",\"Sao Tome and Principe\",\"Saudi Arabia\",\"Senegal\",\"Serbia\",\"Seychelles\",\"Sierra Leone\",\"Singapore\",\"Sint Maarten (Dutch part)\",\"Slovak Republic\",\"Slovenia\",\"Solomon Islands\",\"Somalia\",\"South Africa\",\"South Sudan\",\"Spain\",\"Sri Lanka\",\"St. Kitts and Nevis\",\"St. Lucia\",\"St. Martin (French part)\",\"St. Vincent and the Grenadines\",\"Sudan\",\"Suriname\",\"Sweden\",\"Switzerland\",\"Syrian Arab Republic\",\"Tajikistan\",\"Tanzania\",\"Thailand\",\"Timor-Leste\",\"Togo\",\"Tonga\",\"Trinidad and Tobago\",\"Tunisia\",\"Turkey\",\"Turkmenistan\",\"Turks and Caicos Islands\",\"Tuvalu\",\"Uganda\",\"Ukraine\",\"United Arab Emirates\",\"United Kingdom\",\"United States\",\"Uruguay\",\"Uzbekistan\",\"Vanuatu\",\"Venezuela, RB\",\"Vietnam\",\"Virgin Islands (U.S.)\",\"West Bank and Gaza\",\"Yemen, Rep.\",\"Zambia\",\"Zimbabwe\"]\ndeveloping_economies = [\"Algeria\", \"Egypt, Arab Rep.\", \"Libya\", \"Mauritania\", \"Morocco\", \"Sudan\", \"Tunisia\", \"Cameroon\", \"Central African Republic\", \"Chad\", \"Congo, Rep.\", \"Equatorial Guinea\", \n\"Sao Tome and Prinicipe\", \"Gabon\", \"Burundi\", \"Comoros\", \"Congo, Dem. Rep.\", \"Djibouti\", \"Eritrea\", \"Ethiopia\", \"Kenya\", \"Madagascar\", \"Rwanda\", \"Somalia\", \"South Sudan\", \"Uganda\", \"Tanzania\", \"Angola\", \n\"Botswana\", \"Eswatini\", \"Lesotho\", \"Malawi\", \"Mauritius\", \"Mozambique\", \"Namibia\", \"South Africa\", \"Zambia\", \"Zimbabwe\", \"Benin\", \"Burkina Faso\", \"Cabo Verde\", \"Cote d'Ivoire\", \"Gambia, The\", \"Ghana\", \"Guinea\", \n\"Guinea-Bissau\", \"Liberia\", \"Mali\", \"Niger\", \"Nigeria\", \"Senegal\", \"Sierra Leone\", \"Togo\", \"Brunei Darussalam\", \"Cambodia\", \"China\", \"Korea, Dem. People's Rep.\", \"Fiji\", \"Hong Kong SAR, China\", \"Indonesia\", \"Kiribati\", \"Lao PDR\", \"Malaysia\", \"Mongolia\", \n\"Myanmar\", \"Papua New Guinea\", \"Philippines\", \"Korea, Rep.\", \"Samoa\", \"Singapore\", \"Solomon Islands\", \"Taiwan\", \"Thailand\", \"Timor-Leste\", \"Vanuatu\", \"Vietnam\", \"Afghanistan\", \"Bangladesh\", \"Bhutan\", \"India\", \"Iran, Islamic Rep.\", \"Maldives\", \"Nepal\", \"Pakistan\", \"Sri Lanka\", \"Bahrain\", \"Iraq\", \"Israel\", \"Jordan\", \n\"Kuwait\", \"Lebanon\", \"Oman\", \"Qatar\", \"Saudi Arabia\", \"State of Palestine\", \"Syrian Arab Republic\", \"Turkey\", \"United Arab Emirates\", \"Yemen, Rep.\", \"Bahamas, The\", \"Barbados\", \"Belize\", \"Guyana\", \n\"Jamaica\", \"Suriname\", \"Trinidad and Tobago\", \"Costa Rica\", \"Cuba\", \"Dominican Republic\", \"El Salvador\", \"Guatemala\", \"Haiti\", \"Honduras\", \"Mexico\", \"Nicaragua\", \"Panama\", \"Argentina\", \"Bolivia\", \"Brazil\", \n\"Chile\", \"Colombia\", \"Ecuador\", \"Paraguay\", \"Peru\", \"Uruguay\", \"Venezuela\", \"Venezuela, RB\", 'Seychelles', 'Tonga']\nemerging_economies = [\"Albania\", \"Bosnia and Herzegovina\", \"Montenegro\", \"North Macedonia\", \"Serbia\", \"Armenia\", \"Azerbaijan\", \"Belarus\", \"Georgia\", \"Kazakhstan\", \"Kyrgyz Republic\", \"Moldova\", \"Russian Federation\", \"Tajikistan\", \"Turkmenistan\", \"Ukraine\", \"Uzbekistan\"]\ndeveloped_economies = [\"Canada\", \"United States\", \"Australia\", \"Japan\", \"New Zealand\", \"Austria\", \"Belgium\", \"Denmark\", \"Finland\", \"France\", \"Germany\", \"Greece\", \"Ireland\", \"Italy\", \"Luxembourg\", \"Netherlands\", \"Portugal\", \"Spain\", \"Sweden\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech Republic\", \"Estonia\", \"Hungary\", \"Latvia\", \"Lithuania\", \"Malta\", \"Poland\", \"Romania\", \"Slovak Republic\", \"Slovenia\", \"Iceland\", \"Norway\", \"Switzerland\", \"United Kingdom\"]\n","metadata":{"execution":{"iopub.status.busy":"2022-07-28T10:31:08.416330Z","iopub.execute_input":"2022-07-28T10:31:08.416621Z","iopub.status.idle":"2022-07-28T10:31:08.447708Z","shell.execute_reply.started":"2022-07-28T10:31:08.416564Z","shell.execute_reply":"2022-07-28T10:31:08.446154Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **CELL 3**\n\nThe cell below contains functions which will be used to execute different stages of data spooling, cleaning and model fitting. The code was organised in this format to help ensure clarity in procedure and enable the user some flexibility in changing some inputs into some functions. The following is an explanation of the purpose of each function:\n\n**The spool_values function**: This function is the first call to be made in this code structure. It programmatically accesses the World Bank API and downloads the relevant data for our specified variables and countries. Its inputs is the dictionary-type variable called \"indicators\" above and the list-type variables called \"countries_list above\". It returns a pandas dataframe containing values from 1960 - 2021 (or the most recent year in the database) for all countries in  \"countries_list\" and all variables in \"indicators\". \n\n**The clean_data function**: This function is called second and takes as the resulting dataframe from the \"spool_values\" function as an input. The intention of this function is to systematically reduce missing variables in the dataset. It does this by;\n* It calls in the dataset spooled from the WDI from the spool_values function above.\n* If the NaN_drop variable is True, it executes a conditional statement. This argument in the function uses the NaN_perc variable to drop (delete) rows with missing values less than NaN_perc. For example, if NaN_drop is True and NaN_perc is 60%, then every row in our dataset that has 40% or more of its values missing is deleted from the dataset. For example, if Japan in 1972 has 41% of the variables missing, that year is dropped from our dataset. \n* If the country_drop variable is True, it executes a conditional statement. This argument uses the cut_off variable to drop all data for a country in our dataset that does not have at least a set percentage of the annual data available. For example, if country_drop is True and cut_off is 60%, then if Japan does not have at least 37 years of annual data in the dataset, it is dropped entirely. (1960 â€“ 2021 represents 61 years)\nThe issue of missing data is significant given that we are working with many countries and will eventually fill in missing data in our dataset. The idea is to try as much as possible to maintain the data structure such that annual data and countries that have a lot of missing values are dropped entirely. In the original report we have used a threshold of 50% for missing variables in the row and 50% for number of rows (years) which a country must have to remain in the data.\n!!Any subsequent users can change the cutoff for rows and countrys should they wish to vary the criteria with which missing variables are treated in the context explained above. The values can range from 1 to 100.\n\n**The fill_values function**: The fill_values function is executed on a country-by-country basis. It uses the dataset outputted by the clean_data function above. The function uses the K-nearest neighbor model to make predictions for missing values in our model and fill all missing data. If the neighbors' argument is specified as 3, the model will use the nearest three annual data to a missing datapoint to predict the missing value. \nFor example, in our dataset, if the birth rate variable was missing for Japan in 1972, the model uses 1969, 1970, and 1971 birth rate data points for Japan to predict the missing 1972 value. Please note that this imputation is done on a country-by-country basis. The output of this function is a dataframe will all missing values predicted.\n!! Any subsequent users can change the neighbors argument to values above 3 should they wish to change how the KNN model predicts the missing values. A value of 3 or 5 is usually recommended.\nPlease see the [link](https://towardsdatascience.com/the-use-of-knn-for-missing-values-cf33d935c637) here for more explanation of the KNN imputation technique. \n\n**The visualise_missing function**: The visualize_missing function is used to create a graphical representation of missing values in our dataset. This is simply an informative graph to help us understand which variables in the dataset have the most missing values. This function is applied to the output of the spool_values, clean_data and fill_values functions to see the ratio of missing variables in the dataframe.\n\n**The standardization function**: This function standardizes the dataframe outputed from the \"fill_values\" function. Standardising a dataset involves rescaling the distribution of values so that the mean of observed values is 0 and the standard deviation is 1. This process is essential primarily when the different variables used in ML models have different scales (Brownlee, 2016). This prevents variables that have higher orders from biasing the model.The output of this function is simply the same dataframe but rescaled such that the mean and standard deviation are 0 and 1 respectively.\n\n**The feature_engineering function**: This function simply performs feature engineering by creating three new variables from the variables already in the dataset. We perform feature engineering to create three variables: trade openness (import + export/ GDP), CO2 emission per capita (CO2 emission (kt)/ Total population) and Air Transportation per capita (Air Transportation (number of passengers)/ Total population). The import, export and total population columns are then dropped because they are not among the list of variables which we employ in our modelling. \n!!Any subsequent users should delete this function if they do not intend to have these features (variables) in the dataset which they use to fit their own models. An error will be thrown if the import, export and population variables were not part of the originally spooled variables from the WB database.\n\n**The economy_classification function**: This function will add a column to the output of the \"feature_engineering\" dataset in preparation for the supervised machine learning. The new column is the dependent variable column featuring the three classes necessary for the analysis. Developing economies take the class 0, transition economies take the class 1 and developed economies take the class two. This class assignment is done based on the developing_economies, emerging economies and developed_economies list specified above and culled based on the World Economic Situation and Prospects 2022 report. \n\n**The unsupervised_ML function**: This function fits an usupervised ML model to produce clusters for the dataset. It's arguments (inputs) include:\n*            dataframe; The dataset\n*            year: The specific year for the countries in the dataset on which to run the cluster algorithm on\n*            clusters: The number of clusters to include in our dataset. The report form of this work uses five clusters for the economies in the dataset.\n*            model: Either the KMeans or GMM model.\nThe output of this function is a dataset with a list of countries and the cluster assignment for each country, along with a two principal component analysis variables should the user which to visualise the dimensioanlity reduction of the variables supplied to the model.\n\n**The supervised_ML function**: This function fits a supervised ML model to understand and predict the three classes supplied to the model. It's arguments include:\n*            dataframe; The dataset\n*            split_size: The size of the randomly selected test dataset (the size used for the report is 30%)\n*            clusters: The number of clusters to include in our dataset\n*            model: Either the RFC, SVMC, or XGBC\n*            excluded_country: The country to be excluded should the user which to perform an out of sample prediction. This country is excluded from the model fitting  process and then its class predicted with the fitted model.\nThere are two outputs for this function. First the fitted model, from which the feature importance listing is derived and the out-of-sample test data should the user choose to select one. However, while fitting the model, the confusion matrix is printed.\n!!If the user does not want to include any country for out of sample testing, then this argument should take the value of \"None\".\n\n**The feature_importance_graph function**: This function returns a graph of the feature importance for the variables used in either of the three models in the supervised_ML function. It takes the following arguments:\n* fitted_model: The variable in which the model for the supervised_ml was saved into\n* model_name: Either the RFC, SVMC, or XGBC (this must align with the model into which the supervised_ML was saved into.)","metadata":{}},{"cell_type":"code","source":"def spool_values(variables, countries):\n    \"\"\"This is a function that returns the listed indicator values\n        Args:\n            indicators; a dictionary containing required indicator codes and name\n            countries_list: A list of countries which we require for our dataset\n        Returns: a dataframe of data queried from the World Bank Development Indicators DataBase\n        \"\"\"\n    wbdata.get_source()\n    wbdata.get_indicator(source=2)\n    print(\"Spooling data for \" + str(len(variables)) + \" variables, across \" + str(len(countries)) + \" economies.\")\n    df = wbdata.get_dataframe(variables, country=\"all\", cache=True)\n    df = df.reset_index(level=0)\n    df = df.reset_index(level=0)\n    final = df[df['country'].isin(countries)]\n    return final\n\n\ndef clean_data(dataframe, NaN_drop, NaN_perc, country_drop, cutoff):\n    \"\"\"This is a function that cleans a dataframe based on the number of missing variables that exists in each row. It also drops countries that have annual data less than the cutoff\n        Args:\n            dataframe; A dataframe containing the panel data\n            NaN_drop; A True or false variable which specifies whether rows with missing values above our threshold should be dropped. \n            NaN_perc; delete the rows of a dataframe based on NaN percentage. It means by the percentage of missing values the rows contains. For example, deleting dataframe rows where NaN value are either 25% or more than 25%. Range: 0 -100\n            country_drop: A True or false variable which specifies whether the country with annual date below the cutoff should be dropped. \n            cutoff; The minimum number of annual data each country should have. A country is dropped if it has less. Range: 0 - 100\n        Returns: a dataframe with less missing rows and countries\n        \"\"\"\n    print(\"The original shape of our dataset is: \" + str(dataframe.shape) + \" with \" + str(dataframe['country'].nunique()) + \" countries\")\n    if NaN_drop == True:\n        min_count =  int(((NaN_perc)/100)*dataframe.shape[1] + 1)\n        print(\"Each row in our dataset must have at least \" + str(NaN_perc) + \"% of the values present\")\n        print(\"We will drop rows that do not meet this condition\")\n        print(\"\")\n        mod_df = df.dropna(axis=0, thresh=min_count)\n        cleaned_df = mod_df\n    else:\n        cleaned_df = dataframe\n        mod_df = dataframe\n    if country_drop == True:\n        last_year = int(mod_df['date'].max())\n        first_year = int(mod_df['date'].min())\n        cutoff_value = int(round((cutoff/100)*(last_year - first_year)))\n        print(\"Each country in our dataset must have at least \" + str(cutoff) + \"% of the years present\")\n        print(\"We will completely drop countries that do not meet this condition\")\n        print('')\n        count = pd.DataFrame(mod_df['country'].value_counts())\n        count = count.reset_index(level=0)\n        count_2 = count[count['country']>= cutoff_value]\n        qualified_countries = sorted(list(count_2['index']))\n        cleaned_df = mod_df[mod_df['country'].isin(qualified_countries)]\n        print(\"The new shape of our dataset is: \" + str(cleaned_df.shape) + \" with \" + str(cleaned_df['country'].nunique()) + \" countries\")\n        print(\"\")\n    else:\n        print(\"The new shape of our dataset is: \" + str(cleaned_df.shape) + \" with \" + str(cleaned_df['country'].nunique()) + \" countries\")\n        print('')\n    return cleaned_df\n\n\ndef fill_values(dataframe, neighbors):\n    \"\"\"A K- Nearest Neighbor model which fills the NAs in our dataframe\n        Args:\n            dataset; The dataset\n            neighbors: A KNN parameter for the neigbors used in modelling. Usually integer 3 or 5 \n        Returns: a dataframe with all missing values (NaNs) imputed\n        \"\"\"\n    country_list = sorted(set(list(dataframe['country'])))\n    dataset_columns = list(dataframe.columns)\n    filled_data = pd.DataFrame()\n    for country in country_list:\n        print(\" Now imputing missing variable for \" + str(country))\n        iteration_incomplete_dataset = dataframe.loc[dataframe['country'].isin([country])]\n        iteration_incomplete_dataset.drop(['country'], axis=1, inplace=True)\n        filled_country_data = pd.DataFrame(KNN(k=neighbors).fit_transform(iteration_incomplete_dataset))\n        complete_data = filled_country_data\n        complete_data.insert(1, 'country', country)\n        filled_data = pd.concat([filled_data, complete_data])\n    filled_data.columns = dataset_columns\n    filled_data.date = filled_data.date.astype(int)\n    return filled_data\n\ndef visualise_missing(dataframe):\n    \"\"\"This function will visualise the percentage of missing variables in a dataframe\n        Args:\n            dataframe; The dataset\n        Returns: A graphical representation of missing variable across all variables in the inputted dataframe\n        \"\"\"\n    \n    #Visualizing Missing Data using Seaborn\n    plt.figure(figsize=(10,6))\n    sns.displot(data=dataframe.isna().melt(value_name=\"Variable Missing\"), y=\"variable\", hue=\"Variable Missing\", multiple=\"fill\", aspect=1.25)\n    plt.savefig(\"visualizing_missing_data_with_barplot_Seaborn_distplot.png\", dpi=100)\n    return\n\ndef standardization(dataframe):\n    \"\"\"This function will standardize the variables in our dataset cause it to have a mean of zero and standard deviation of 1.\n        Args:\n            dataframe; The dataset\n        Returns: A dataset with the list of countries with all variables standardized\n        \"\"\"\n    scaler= StandardScaler()\n    standardized = dataframe.copy()\n    standardized = standardized.reset_index(drop=True)\n    country_column = standardized[['country', 'date']]\n    standardized.drop(\"country\", axis=1, inplace=True)\n    standardized.drop(\"date\", axis=1, inplace=True)\n    standardized_data = scaler.fit_transform(standardized)\n    standardized_df = pd.DataFrame(standardized_data, columns=standardized.columns)\n    standardized_df = country_column.join(standardized_df)\n    return standardized_df\n\ndef feature_engineering(filled_data):\n    \"\"\"This function will help us create some specified variables such as trade openness from the complete dataset\n        Args:\n            dataframe; The dataset\n        Returns: A dataset with the the complete columns which the analysis requires\n        \"\"\"\n    #This code is the feature engineering for tradeopenness and Co2 emission (kt per capita)\n    filled_data[\"Trade Openness\"] = (filled_data[\"Imports of goods and services (constant 2015 US$)\"] + filled_data[\"Exports of goods and services (constant 2015 US$)\"]) / filled_data[\"GDP (constant 2015 US$)\"]\n    filled_data[\"CO2 emissions (kt per capita)\"] = filled_data[\"CO2 emissions (kt)\"]/ filled_data[\"Population, total\"]\n    filled_data[\"Air transport, passengers carried per capita\"] = filled_data[\"Air transport, passengers carried\"]/ filled_data[\"Population, total\"]\n    filled_data.drop(\"Imports of goods and services (constant 2015 US$)\", axis=1, inplace=True)\n    filled_data.drop(\"Exports of goods and services (constant 2015 US$)\", axis=1, inplace=True)\n    filled_data.drop(\"Population, total\", axis=1, inplace=True)\n    filled_data.drop(\"CO2 emissions (kt)\", axis=1, inplace=True)\n    filled_data.drop(\"Air transport, passengers carried\", axis=1, inplace=True)\n    ##reindex columns\n    full_data = filled_data[['date', 'country', \"Trade Openness\", 'Domestic general government health expenditure (% of GDP)', 'Out-of-pocket expenditure (% of current health expenditure)', 'Government expenditure on education, total (% of government expenditure)', 'Electric power consumption (kWh per capita)', 'Gross capital formation (% of GDP)', 'Foreign direct investment, net (BoP, current US$)', 'Military expenditure (% of GDP)', 'GDP per capita (constant 2015 US$)', 'Unemployment, total (% of total labor force) (modeled ILO estimate)', 'Fertility rate, total (births per woman)', 'Mortality rate, infant (per 1,000 live births)', 'Life expectancy at birth, total (years)', 'School enrollment, primary (gross), gender parity index (GPI)', 'Industry (including construction), value added (% of GDP)', 'Manufacturing, value added (% of GDP)', \"Air transport, passengers carried per capita\", \"CO2 emissions (kt per capita)\", 'Mineral rents (% of GDP)', 'Food imports (% of merchandise imports)', 'CPIA transparency, accountability, and corruption in the public sector rating (1=low to 6=high)', 'CPIA quality of budgetary and financial management rating (1=low to 6=high)', 'CPIA property rights and rule-based governance rating (1=low to 6=high)', 'CPIA trade rating (1=low to 6=high)']]\n    return full_data\n\ndef economy_classification(dataset):\n    \"\"\"This function will create (an extra column) the dependent variable column with three classes in prepartion for the supervised ML model.\n        Args:\n            dataframe; The dataset\n        Returns: A dataset with an extra column which is the economic classification; developing (0), transitiong (1), developed (2)\n         \"\"\"\n    ml_data = dataset.copy()\n    def dictionary_function(dataframe):   \n        myDict = {}\n        myDict[\"0\"] = developing_economies\n        myDict[\"1\"] = emerging_economies\n        myDict[\"2\"] = developed_economies\n        dataframe = dataframe.copy()\n\n        if dataframe['country'] in (developing_economies):\n            return 0\n        elif dataframe['country'] in (emerging_economies):\n            return 1\n        elif dataframe['country'] in (developed_economies):\n            return 2\n        else:\n            return \"missing\"\n    \n    ml_data['Economy'] = ml_data.apply(dictionary_function, axis=1)\n    ml_data.drop(ml_data.index[ml_data['Economy'] == \"missing\"], inplace=True)\n    return ml_data\n\ndef unsupervised_ML(dataframe, year, clusters, model):\n    \"\"\"This function will run an unsupervised machine learning with specified clusters for a specific year in our dataset.\n        Args:\n            dataframe; The dataset\n            year: The year to run the cluster on\n            clusters: The number of clusters to include in our dataset\n            model: Either the KMeans or Gaussian Mixture Model\n        Returns: A dataset with the list of countries, the Principle Component Analysis 2-dimensional representation and the relevant clusters.\n        \"\"\"\n    data = dataframe.copy()\n    data = data.loc[data['date'] == int(year)]\n    data.index = range(len(data.index))\n    country_subset_column = data[['country']]\n    data = data.dropna()\n    #backup = df2.copy()\n    data = data.iloc[:,2:]\n    #df2_backup = df2.copy()\n    \n    if model == \"KMeans\":\n        clustering_kmeans = KMeans(n_clusters=clusters, random_state=1)\n        pca_num_components = 2\n        reduced_data = PCA(n_components=pca_num_components).fit_transform(data)\n        pca = pd.DataFrame(reduced_data,columns=['pca1','pca2'])\n        pca['clusters'] = clustering_kmeans.fit_predict(data)\n        result = country_subset_column.join(pca)\n        return result\n        \n    elif model == \"GMM\":\n        gmm = GaussianMixture(n_components=(int(clusters)), random_state=1)\n        pca_num_components = 2\n        reduced_data = PCA(n_components=pca_num_components).fit_transform(data)\n        pca = pd.DataFrame(reduced_data,columns=['pca1','pca2'])\n        gmm.fit(data)\n        probs = gmm.predict_proba(data)\n        props = probs.round(3)\n        pca['clusters'] = gmm.fit_predict(data)\n        probs = pd.DataFrame(probs,columns=['Cluster 0 Prob','Cluster 1 Prob', 'Cluster 2 Prob','Cluster 3 Prob', 'Cluster 4 Prob'])\n        probs = probs.round({'Cluster 0 Prob' : 3,'Cluster 1 Prob' : 3, 'Cluster 2 Prob' : 3,'Cluster 3 Prob' : 3, 'Cluster 4 Prob' : 3})\n        result = country_subset_column.join(pca)\n        result = result.join(probs)\n        return result\n        \n    else:\n        print(\"You have not selected either a KMeans model or a Gaussian Mixture Model(GMM). Please reinput the correct function parameters\")\n        \n        \ndef supervised_ml(dataframe, split_size, model, excluded_country):\n    \"\"\"This function will run a supervised machine learning with a split ratio for the size of the test dataset.\n        Args:\n            dataframe; The dataset\n            split_size: The size of the randomly selected test dataset\n            model: Either the RFC, SVMC, or XGBC\n            excluded_country: The country to be excluded should the user which to perform an out of sample prediction. This country is excluded from the model fitting process and then its class predicted with the fitted model.\n        Returns: A fitted Machine Learning Model\n        \"\"\"\n    input_df= dataframe.copy()\n    test_country = pd.DataFrame()\n    \n    if excluded_country == \"None\":\n        print(\"We have not excluded any country to test the prediction accuracy.\")\n    else:\n        print(\"We will exclude \" +str(excluded_country) + \" from the learning process of the various ML models, then predict its classification later\")\n        excluded_country_df = input_df.loc[input_df['country'] == str(excluded_country)]\n        test_country = test_country.append(excluded_country_df)\n        test_country = test_country.reset_index(drop= True)\n    \n    input_df.drop(input_df.index[input_df['country'] == excluded_country], inplace = True)\n    input_df.drop(columns = [\"country\",\"date\"], inplace=True) \n    input_df = input_df.dropna()    \n    input_df = sklearn.utils.shuffle(input_df)\n    input_df = input_df.reset_index(drop= True)\n    input_df[\"Economy\"] = input_df['Economy'].astype('int')\n    \n    X = input_df.drop(columns= 'Economy')\n    y = input_df['Economy'] \n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size= split_size, random_state= 1 )\n    smote = SMOTE(random_state=1)\n    x_train_balanced, y_balanced = smote.fit_resample(x_train, y_train)\n    \n    if model == \"RFC\":\n        clf_forest=RandomForestClassifier(random_state=1)\n        clf_forest.fit(x_train_balanced, y_balanced)\n        y_pred_forest=clf_forest.predict(x_test)\n        print(\"Accuracy for Random Forest Classificer:\",metrics.accuracy_score(y_test, y_pred_forest))\n        print(classification_report(y_test, y_pred_forest))\n        if excluded_country == \"None\":  \n            return clf_forest, test_country\n        else:\n            test_country_variables = test_country.drop(['Economy', 'country', 'date'], axis=1)\n            test_country_prediction = clf_forest.predict(test_country_variables)\n            result = pd.DataFrame(test_country_prediction,columns=['Classification'])\n            test_country[\"Classification\"] = result[\"Classification\"]  \n            return clf_forest, test_country\n        \n    elif model == \"SVMC\":\n        svmc=SVC() \n        svmc.fit(x_train_balanced, y_balanced)\n        y_pred_svmc = svmc.predict(x_test)\n        print(\"Accuracy for Support Vector Model Classifier:\",metrics.accuracy_score(y_test, y_pred_svmc))\n        print(classification_report(y_test, y_pred_svmc))\n        if excluded_country == \"None\":\n            return svmc, test_country\n        else:\n            test_country_variables = test_country.drop(['Economy', 'country', 'date'], axis=1)\n            test_country_prediction = svmc.predict(test_country_variables)\n            result = pd.DataFrame(test_country_prediction,columns=['Classification'])\n            test_country[\"Classification\"] = result[\"Classification\"]      \n            return svmc, test_country\n    \n    elif model == \"XGBC\":\n        clf_xgb = XGBClassifier(random_state=1) \n        clf_xgb.fit(x_train_balanced, y_balanced)\n        y_pred_xgb = clf_xgb.predict(x_test)\n        accuracy = metrics.accuracy_score(y_test, y_pred_xgb)\n        print(\"Accuracy for XGBoost Classifier: %.4f%%\" % (accuracy *100))\n        print(classification_report(y_test, y_pred_xgb))\n        if excluded_country == \"None\":\n            return clf_xgb, test_country\n        else:\n            test_country_variables = test_country.drop(['Economy', 'country', 'date'], axis=1)\n            test_country_prediction = clf_xgb.predict(test_country_variables)\n            result = pd.DataFrame(test_country_prediction,columns=['Classification'])\n            test_country[\"Classification\"] = result[\"Classification\"]      \n            return clf_xgb, test_country\n        \n    else:\n        print(\"You have not selected either a RFC/ SVMC or XGBC. Please reinput the correct function parameters\")\n\n\ndef feature_importance_graph(fitted_model, model_name):\n    \"\"\"This function will return a graph showing the feature importance for the fitted ML model\n        Args:\n            fitted_model: The variable in which the model for the supervised_ml was defined in\n            model_name: Either the RFC, SVMC, or XGBC\n        Returns: A dataset with the features (variables) and their weighted importance for the model's classification goal. It also plots a graph.\n        \"\"\"\n    if model_name == \"RFC\" or model_name == \"XGBC\":\n        features = ml_data.drop(columns= [\"Economy\", \"country\", 'date'])\n        predictors = [x for x in features.columns]\n        feat_imp = pd.Series(fitted_model.feature_importances_, predictors).sort_values(ascending=False)\n        feat_imp = feat_imp[0:50]\n        plt.rcParams['figure.figsize'] = 20, 5\n        feat_imp.plot(kind='bar', title='Feature Importance')\n        plt.ylabel('Feature Importance Score')\n        feat_imp = feat_imp.copy()\n        feature_importance_df = pd.DataFrame({'Feature': feat_imp.index, str(model_name): feat_imp.values})\n        return feature_importance_df\n        \n    elif model_name == \"SVMC\":\n        print(\"The Support Vector Machine Model was fitted using the default kernel: rbf. Thus it cannot output a feature importance listing\")\n\n    else:\n        print(\"You have not selected either a RFC/ SVMC or XGBC. Please reinput the correct function parameters\")","metadata":{"execution":{"iopub.status.busy":"2022-07-28T11:43:58.455563Z","iopub.execute_input":"2022-07-28T11:43:58.455935Z","iopub.status.idle":"2022-07-28T11:43:58.531738Z","shell.execute_reply.started":"2022-07-28T11:43:58.455896Z","shell.execute_reply":"2022-07-28T11:43:58.530492Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# **CELL 4**\nThe cell below will simply execute the function to pull the necessary dataset from the WB Database and visualise missing variables ratio.","metadata":{}},{"cell_type":"code","source":"#This code will pull the relevant datasets from the World Bank repository\ndf = spool_values(indicators, countries_list)\nvisualise_missing(df)","metadata":{"execution":{"iopub.status.busy":"2022-07-28T10:31:08.533193Z","iopub.execute_input":"2022-07-28T10:31:08.534014Z","iopub.status.idle":"2022-07-28T10:39:44.579502Z","shell.execute_reply.started":"2022-07-28T10:31:08.533967Z","shell.execute_reply":"2022-07-28T10:39:44.578789Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# **CELL 5**\nThe cell below will simply execute the function to clean missing variables based on the criteria inputed and visualise the resulting missing variables.","metadata":{}},{"cell_type":"code","source":"#This code will delimit the dataset by dropping countries with too many missing variables\ncleaned_df = clean_data(df, True, 50, True, 50)\nvisualise_missing(cleaned_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-28T10:39:44.580941Z","iopub.execute_input":"2022-07-28T10:39:44.581734Z","iopub.status.idle":"2022-07-28T10:39:46.318235Z","shell.execute_reply.started":"2022-07-28T10:39:44.581687Z","shell.execute_reply":"2022-07-28T10:39:46.317331Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# **CELL 6**\nThe cell below will simply execute the function to fill missing variables in our dataset using KNN imputation technique.","metadata":{}},{"cell_type":"code","source":"#This code will fill the missing variables in the dataset\nfilled_data = fill_values(cleaned_df, 3)\n#visualise_missing(filled_data)","metadata":{"execution":{"iopub.status.busy":"2022-07-28T10:39:46.319581Z","iopub.execute_input":"2022-07-28T10:39:46.320298Z","iopub.status.idle":"2022-07-28T10:39:50.608822Z","shell.execute_reply.started":"2022-07-28T10:39:46.320246Z","shell.execute_reply":"2022-07-28T10:39:50.608134Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# **CELL 7**\nThe cell below will simply execute the function to perform feature engineering and create the variables which were specified before.","metadata":{}},{"cell_type":"code","source":"#This code is the feature engineering for tradeopenness and Co2 emission (kt per capita)\nfull_data = feature_engineering(filled_data)","metadata":{"execution":{"iopub.status.busy":"2022-07-28T10:39:50.609846Z","iopub.execute_input":"2022-07-28T10:39:50.610076Z","iopub.status.idle":"2022-07-28T10:39:50.628509Z","shell.execute_reply.started":"2022-07-28T10:39:50.610045Z","shell.execute_reply":"2022-07-28T10:39:50.627430Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# **CELL 8**\nThe cell below will simply execute the function to standardize all the data in the dataset.","metadata":{}},{"cell_type":"code","source":"#This executes the standardisation functions\nstandardized_df = standardization(full_data)","metadata":{"execution":{"iopub.status.busy":"2022-07-28T10:39:50.629895Z","iopub.execute_input":"2022-07-28T10:39:50.630135Z","iopub.status.idle":"2022-07-28T10:39:50.649983Z","shell.execute_reply.started":"2022-07-28T10:39:50.630105Z","shell.execute_reply":"2022-07-28T10:39:50.648941Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# **CELL 9**\nThe cell below will simply execute the function to perform the unsupervised ML on a specific year using 5 clusters and a specified model: KMeans or GMM.","metadata":{}},{"cell_type":"code","source":"#This executes the specified unsupervised ML model\nKMeans_unsupervised = unsupervised_ML(standardized_df, 2000, 5, \"KMeans\")","metadata":{"execution":{"iopub.status.busy":"2022-07-28T10:39:50.652919Z","iopub.execute_input":"2022-07-28T10:39:50.653219Z","iopub.status.idle":"2022-07-28T10:39:50.741035Z","shell.execute_reply.started":"2022-07-28T10:39:50.653182Z","shell.execute_reply":"2022-07-28T10:39:50.739859Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# **CELL 10**\nThe cell below will simply execute the function to create the 3 classes needed for the dependent variable, in preparation for the supervised ML.","metadata":{}},{"cell_type":"code","source":"#Label economies: developed, developing and transitioning in preparation for the supervised ML model\nml_data = economy_classification(standardized_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-28T10:39:50.742446Z","iopub.execute_input":"2022-07-28T10:39:50.742697Z","iopub.status.idle":"2022-07-28T10:39:51.135544Z","shell.execute_reply.started":"2022-07-28T10:39:50.742660Z","shell.execute_reply":"2022-07-28T10:39:51.134815Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# **CELL 11**\nThe cell below will simply execute the function to perform the supervised ML on our data using a 30% test data split for validation and a specified model: RFC, SVMC or XGBC.","metadata":{}},{"cell_type":"code","source":"#This executes the specified supervised ML model\nmodel_output, test_country = supervised_ml(ml_data, 0.3, \"SVMC\", \"None\")","metadata":{"execution":{"iopub.status.busy":"2022-07-28T11:58:52.911258Z","iopub.execute_input":"2022-07-28T11:58:52.911598Z","iopub.status.idle":"2022-07-28T11:58:53.761792Z","shell.execute_reply.started":"2022-07-28T11:58:52.911564Z","shell.execute_reply":"2022-07-28T11:58:53.760807Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"#This cell will output the prediction of the selected model as against the world bank classificiation for a selected out-of-sample country (if any has been slected)\ntest_country.head(35)","metadata":{"execution":{"iopub.status.busy":"2022-07-28T11:56:00.945483Z","iopub.execute_input":"2022-07-28T11:56:00.946417Z","iopub.status.idle":"2022-07-28T11:56:00.998980Z","shell.execute_reply.started":"2022-07-28T11:56:00.946355Z","shell.execute_reply":"2022-07-28T11:56:00.997985Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"# **CELL 12**\nThe cell below will simply execute the function to visualise the variable importance of the specific ML model executed above. The output can also be analysed as a dataframe.","metadata":{}},{"cell_type":"code","source":"#This will visualise the feature importance of the model fitted above\nRFC = feature_importance_graph(model_output, \"RFC\")","metadata":{"execution":{"iopub.status.busy":"2022-07-28T11:42:05.996362Z","iopub.execute_input":"2022-07-28T11:42:05.996799Z","iopub.status.idle":"2022-07-28T11:42:06.560481Z","shell.execute_reply.started":"2022-07-28T11:42:05.996757Z","shell.execute_reply":"2022-07-28T11:42:06.559831Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"RFC.to_excel(\"RFC Output.xlsx\")","metadata":{"execution":{"iopub.status.busy":"2022-07-28T11:14:52.566670Z","iopub.execute_input":"2022-07-28T11:14:52.567097Z","iopub.status.idle":"2022-07-28T11:14:52.590665Z","shell.execute_reply.started":"2022-07-28T11:14:52.567038Z","shell.execute_reply":"2022-07-28T11:14:52.589788Z"},"trusted":true},"execution_count":29,"outputs":[]}]}